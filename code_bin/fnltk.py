from nltk.tokenize import sent_tokenize

text = "这是一段示例文本。它包含了两个句子。"
sentences = sent_tokenize(text)

print(sentences)
